{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "final_df = pd.DataFrame(columns=['content', 'type'])\n",
    "\n",
    "for x in os.listdir('car_nlp_csv'):\n",
    "    a = pd.read_csv('car_nlp_csv//'+x)\n",
    "    final_df = pd.concat([final_df, a], ignore_index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>type</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145096</th>\n",
       "      <td>PRIUS 安全性 召回 更新 注意 事項 大陸 台灣 發生數 更新 失敗 災情 起初 多數...</td>\n",
       "      <td>Toyota_prius</td>\n",
       "      <td>25185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138570</th>\n",
       "      <td>換心 進化 Toyota 小改款 Vios Yaris 試駕 舊版 加速 實測 Vios Y...</td>\n",
       "      <td>Toyota_vios</td>\n",
       "      <td>18659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60230</th>\n",
       "      <td>古董 一代 CRV 準備 進場 底盤 大修 可否 神人 開示 頭好 壯壯 17 一代 CRV...</td>\n",
       "      <td>Honda_crv</td>\n",
       "      <td>15552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117799</th>\n",
       "      <td>15 頻道 年度 飆榜 Subaru Forester 2.0 XS 登台 說真的 喜歡 參...</td>\n",
       "      <td>Subaru_impreza</td>\n",
       "      <td>2982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90540</th>\n",
       "      <td>變速箱 濾網 更換 價格 爬文 得知 原廠 並無此 保養 fortis1.8 快八萬 公里 ...</td>\n",
       "      <td>Mitsubishi_fortis</td>\n",
       "      <td>4228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114072</th>\n",
       "      <td>308 1.6 hdi 容易 開過 那麼多 部車 這一 部車 懊惱 3081.6 hdi 買...</td>\n",
       "      <td>Peugeot_308</td>\n",
       "      <td>517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62511</th>\n",
       "      <td>CRV 2.4 VTI 保險 乙式 自負額 竊盜 10% 意外 200 400 50 乘客 ...</td>\n",
       "      <td>Honda_crv</td>\n",
       "      <td>17833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108728</th>\n",
       "      <td>BIG TIIDA 南部 成交 3q 比單 私密 購車 1.6 五門 掀背 豪華版 售價 6...</td>\n",
       "      <td>Nissan_tiida</td>\n",
       "      <td>10074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104146</th>\n",
       "      <td>Sentra 180 BAS 料號 47210 YS000 Sentra 180N16air...</td>\n",
       "      <td>Nissan_sentra</td>\n",
       "      <td>5492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54053</th>\n",
       "      <td>civic vti 232011 CIVICVTI 單已 下訂 原廠 防盜 識別碼 腳踏墊 ...</td>\n",
       "      <td>Honda_civic</td>\n",
       "      <td>9375.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163289 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content               type  \\\n",
       "145096  PRIUS 安全性 召回 更新 注意 事項 大陸 台灣 發生數 更新 失敗 災情 起初 多數...       Toyota_prius   \n",
       "138570  換心 進化 Toyota 小改款 Vios Yaris 試駕 舊版 加速 實測 Vios Y...        Toyota_vios   \n",
       "60230   古董 一代 CRV 準備 進場 底盤 大修 可否 神人 開示 頭好 壯壯 17 一代 CRV...          Honda_crv   \n",
       "117799  15 頻道 年度 飆榜 Subaru Forester 2.0 XS 登台 說真的 喜歡 參...     Subaru_impreza   \n",
       "90540   變速箱 濾網 更換 價格 爬文 得知 原廠 並無此 保養 fortis1.8 快八萬 公里 ...  Mitsubishi_fortis   \n",
       "...                                                   ...                ...   \n",
       "114072  308 1.6 hdi 容易 開過 那麼多 部車 這一 部車 懊惱 3081.6 hdi 買...        Peugeot_308   \n",
       "62511   CRV 2.4 VTI 保險 乙式 自負額 竊盜 10% 意外 200 400 50 乘客 ...          Honda_crv   \n",
       "108728  BIG TIIDA 南部 成交 3q 比單 私密 購車 1.6 五門 掀背 豪華版 售價 6...       Nissan_tiida   \n",
       "104146  Sentra 180 BAS 料號 47210 YS000 Sentra 180N16air...      Nissan_sentra   \n",
       "54053   civic vti 232011 CIVICVTI 單已 下訂 原廠 防盜 識別碼 腳踏墊 ...        Honda_civic   \n",
       "\n",
       "        Unnamed: 0  \n",
       "145096     25185.0  \n",
       "138570     18659.0  \n",
       "60230      15552.0  \n",
       "117799      2982.0  \n",
       "90540       4228.0  \n",
       "...            ...  \n",
       "114072       517.0  \n",
       "62511      17833.0  \n",
       "108728     10074.0  \n",
       "104146      5492.0  \n",
       "54053       9375.0  \n",
       "\n",
       "[163289 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "final_df = shuffle(final_df)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ford_focus              13280\n",
       "Toyota_altis            10817\n",
       "Honda_civic              8147\n",
       "Honda_crv                7951\n",
       "VK_golf                  5795\n",
       "Toyota_camry             4716\n",
       "Toyota_rav4              4551\n",
       "Nissan_livina            4422\n",
       "Ford_mondeo              4362\n",
       "Mitsubishi_lancer        4300\n",
       "Ford_fiesta              4246\n",
       "Honda_fit                4223\n",
       "Ford_kuga                4157\n",
       "Mazda_mazda3             4001\n",
       "Nissan_tiida             3692\n",
       "Mitsubishi_fortis        3552\n",
       "Mitsubishi_outlander     3100\n",
       "Honda_accord             2999\n",
       "Volvo_s60                2655\n",
       "Toyota_yaris             2613\n",
       "Luxgen_u6                2573\n",
       "Nissan_sentra            2482\n",
       "Volvo_xc60               2331\n",
       "Subaru_forester          2253\n",
       "Hyundai_elantra          2176\n",
       "Ford_escape              2120\n",
       "BMW_320                  2075\n",
       "BMW_520                  2058\n",
       "Toyota_vios              2056\n",
       "VK_tiguan                2038\n",
       "Audi_a4                  1994\n",
       "Nissan_teana             1940\n",
       "Mazda_cx-5               1798\n",
       "Subaru_legacy            1789\n",
       "VK_passat                1748\n",
       "Hyundai_ix35             1728\n",
       "Toyota_prius             1596\n",
       "Luxgen_s5                1465\n",
       "BMW_x5                   1413\n",
       "Volvo_v60                1409\n",
       "Mitsubishi_colt plus     1390\n",
       "Mazda_mazda6             1316\n",
       "Nissan_x-trail           1311\n",
       "Peugeot_308              1262\n",
       "Ford_tierra              1245\n",
       "Audi_a3                  1233\n",
       "Mazda_mazda5             1225\n",
       "Benz_c200                1150\n",
       "Audi_tt                  1137\n",
       "BMW_x3                   1078\n",
       "BMW_m3                   1063\n",
       "Audi_a6                  1055\n",
       "Nissan_march             1054\n",
       "Volvo_v50                1053\n",
       "Subaru_impreza           1052\n",
       "Honda_city               1028\n",
       "Benz_c300                1012\n",
       "Luxgen_s3                1004\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = final_df['content'].tolist()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "Y = final_df['type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(Y)\n",
    "# convert integers to dummy variables (one hot encoding)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.max(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# splitting data into training set and test set. If random_state is set to an integer, the split datasets are fixed.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, dummy_y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 300)         4500      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1000, 256)         230656    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 334, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 334, 128)          98432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 112, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 112, 64)           24640     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7168)              28672     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1835264   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 58)                14906     \n",
      "=================================================================\n",
      "Total params: 2,237,070\n",
      "Trainable params: 2,222,734\n",
      "Non-trainable params: 14,336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Convolution1D, Flatten, Dropout, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import  BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "vocab_size = np.max([np.max(X_train[i]) for i in range(X_train.shape[0])]) + 1  # 这里1 代表空格，其索引被认为是0。\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=1000))\n",
    "model.add(Convolution1D(256, 3, padding='same'))\n",
    "model.add(MaxPool1D(3,3,padding='same'))\n",
    "model.add(Convolution1D(128, 3, padding='same'))\n",
    "model.add(MaxPool1D(3,3,padding='same'))\n",
    "model.add(Convolution1D(64, 3, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization()) # (批)规范化层\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(58,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "# Compile model\n",
    "EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 100\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "estop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "logger = CSVLogger('model_textcnn0915.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big data\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 130631 samples, validate on 32658 samples\n",
      "Epoch 1/20\n",
      "130631/130631 [==============================] - 221s 2ms/step - loss: 1.0578 - accuracy: 0.7014 - val_loss: 0.9477 - val_accuracy: 0.7353\n",
      "Epoch 2/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.7542 - accuracy: 0.7616 - val_loss: 0.8733 - val_accuracy: 0.7305\n",
      "Epoch 3/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.6812 - accuracy: 0.7763 - val_loss: 0.8831 - val_accuracy: 0.7348\n",
      "Epoch 4/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.6142 - accuracy: 0.7912 - val_loss: 1.5143 - val_accuracy: 0.7142\n",
      "Epoch 5/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.5605 - accuracy: 0.8033 - val_loss: 0.9246 - val_accuracy: 0.7280\n",
      "Epoch 6/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.5077 - accuracy: 0.8166 - val_loss: 1.7919 - val_accuracy: 0.6915\n",
      "Epoch 7/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.4641 - accuracy: 0.8287 - val_loss: 1.1251 - val_accuracy: 0.7139\n",
      "Epoch 8/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.4284 - accuracy: 0.8396 - val_loss: 1.0739 - val_accuracy: 0.6970\n",
      "Epoch 9/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.3995 - accuracy: 0.8482 - val_loss: 1.1193 - val_accuracy: 0.6767\n",
      "Epoch 10/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.3750 - accuracy: 0.8551 - val_loss: 1.0583 - val_accuracy: 0.6993\n",
      "Epoch 11/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.3578 - accuracy: 0.8600 - val_loss: 1.2445 - val_accuracy: 0.7077\n",
      "Epoch 12/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.3409 - accuracy: 0.8642 - val_loss: 1.3388 - val_accuracy: 0.6989\n",
      "Epoch 13/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.3254 - accuracy: 0.8691 - val_loss: 1.2489 - val_accuracy: 0.7013\n",
      "Epoch 14/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.3116 - accuracy: 0.8731 - val_loss: 1.3976 - val_accuracy: 0.7026\n",
      "Epoch 15/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.3022 - accuracy: 0.8765 - val_loss: 1.3344 - val_accuracy: 0.7007\n",
      "Epoch 16/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.2940 - accuracy: 0.8790 - val_loss: 1.3004 - val_accuracy: 0.6976\n",
      "Epoch 17/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.2845 - accuracy: 0.8814 - val_loss: 1.2309 - val_accuracy: 0.6940\n",
      "Epoch 18/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.2772 - accuracy: 0.8831 - val_loss: 1.5155 - val_accuracy: 0.6970\n",
      "Epoch 19/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.2698 - accuracy: 0.8852 - val_loss: 1.5722 - val_accuracy: 0.7007\n",
      "Epoch 20/20\n",
      "130631/130631 [==============================] - 218s 2ms/step - loss: 0.2644 - accuracy: 0.8862 - val_loss: 1.2628 - val_accuracy: 0.6885\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=20, batch_size=BS, callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('car_nlp0910_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "feature_path = 'models_dc0910_3.pkl'\n",
    "with open(feature_path, 'wb') as fw:\n",
    "    pickle.dump(cv.vocabulary_, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pickle\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels_copy = lb.fit_transform(Y)\n",
    "with open('lb_nlp0910_3.pickle', 'wb') as f:\n",
    "    f.write(pickle.dumps(lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (20,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-22fd24710e9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'train_acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2794\u001b[0m     return gca().plot(\n\u001b[0;32m   2795\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2796\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m         \"\"\"\n\u001b[0;32m   1664\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1665\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1666\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 270\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (20,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAR+0lEQVR4nO3cf2hV9R/H8dd114Q13XeemxsXreiif1iQ6U10UTi82B+RSKB/hPrHCLH1Q4taufwxseEl8geZodQYRgUjoqAihesIc0OY6SoTctNFjt0Y916tsbXaPOf7x9fu+e672bne7e763ef5+Kuz+9n29t16cj3tXp/jOI4AAJPelHwPAACYGAQfAAxB8AHAEAQfAAxB8AHAEAQfAAzh9zrwzjvv6MyZMyouLtaePXtGPO44jhoaGnT27FlNmzZNVVVVuueee3IyLAAge57P8JctW6aampobPn727Fn9+uuveuutt7Rhwwa999574zogAGB8eAZ//vz5KioquuHjp0+f1iOPPCKfz6d58+apr69PV65cGdchAQBj53lLx0sqlVIgEEhfW5alVCqlkpKSEWdjsZhisZgkKRqNjvVbAwBuwpiDP9o7M/h8vlHPRiIRRSKR9HV3d/dYv/2kEAgElEgk8j3GLYFduNiFi124gsFg1p875t/SsSxr2L+IZDI56rN7AEB+jTn44XBYJ06ckOM4unDhggoLCwk+ANyCPG/p7N+/X+fPn1dvb682btyoNWvWaGhoSJK0YsUKPfDAAzpz5oyef/553Xbbbaqqqsr50ACAm+cZ/M2bN//j4z6fT0899dS4DQQAyA1eaQsAhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhiD4AGAIgg8AhvBncqitrU0NDQ2ybVvLly/XqlWrhj2eSCR08OBB9fX1ybZtPfnkk1q4cGFOBgYAZMcz+LZtq76+Xlu3bpVlWdqyZYvC4bBmz56dPvPJJ59o6dKlWrFihbq6urR7926CDwC3GM9bOh0dHSorK1Npaan8fr/Ky8vV2to67IzP51N/f78kqb+/XyUlJbmZFgCQNc9n+KlUSpZlpa8ty1J7e/uwM6tXr9brr7+uo0eP6s8//9S2bdtG/VqxWEyxWEySFI1GFQgExjL7pOH3+9nFdezCxS5c7GJ8eAbfcZwRH/P5fMOum5ubtWzZMj3++OO6cOGCDhw4oD179mjKlOF/gYhEIopEIunrRCKR7dyTSiAQYBfXsQsXu3CxC1cwGMz6cz1v6ViWpWQymb5OJpMjbtk0NTVp6dKlkqR58+ZpcHBQvb29WQ8FABh/nsEPhUKKx+Pq6enR0NCQWlpaFA6Hh50JBAI6d+6cJKmrq0uDg4OaMWNGbiYGAGTF85ZOQUGBKisrVVdXJ9u2VVFRoTlz5qixsVGhUEjhcFjr16/X4cOH9eWXX0qSqqqqRtz2AQDkl88Z7Sb9BOnu7s7Xt76lcH/SxS5c7MLFLlw5vYcPAJgcCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGMKfyaG2tjY1NDTItm0tX75cq1atGnGmpaVFH3/8sXw+n+666y5t2rRp3IcFAGTPM/i2bau+vl5bt26VZVnasmWLwuGwZs+enT4Tj8f12WefadeuXSoqKtJvv/2W06EBADfP85ZOR0eHysrKVFpaKr/fr/LycrW2tg47c/z4cT366KMqKiqSJBUXF+dmWgBA1jyf4adSKVmWlb62LEvt7e3DznR3d0uStm3bJtu2tXr1ai1YsGDE14rFYorFYpKkaDSqQCAwpuEnC7/fzy6uYxcuduFiF+PDM/iO44z4mM/nG3Zt27bi8bh27NihVCql7du3a8+ePbr99tuHnYtEIopEIunrRCKR7dyTSiAQYBfXsQsXu3CxC1cwGMz6cz1v6ViWpWQymb5OJpMqKSkZdmbmzJl68MEH5ff7NWvWLAWDQcXj8ayHAgCMP8/gh0IhxeNx9fT0aGhoSC0tLQqHw8POLF68WOfOnZMk/f7774rH4yotLc3NxACArHje0ikoKFBlZaXq6upk27YqKio0Z84cNTY2KhQKKRwO6/7779d3332nF154QVOmTNHatWs1ffr0iZgfAJAhnzPaTfoJ8vf/7DUd9ydd7MLFLlzswpXTe/gAgMmB4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABiC4AOAIQg+ABgio+C3tbVp06ZNeu655/TZZ5/d8NypU6e0Zs0aXbx4cdwGBACMD8/g27at+vp61dTUaN++fWpublZXV9eIc3/88Ye++uorzZ07NyeDAgDGxjP4HR0dKisrU2lpqfx+v8rLy9Xa2jriXGNjo1auXKmpU6fmZFAAwNj4vQ6kUilZlpW+tixL7e3tw850dnYqkUho0aJF+vzzz2/4tWKxmGKxmCQpGo0qEAhkO/ek4vf72cV17MLFLlzsYnx4Bt9xnBEf8/l86X+2bVtHjhxRVVWV5zeLRCKKRCLp60Qikemck1ogEGAX17ELF7twsQtXMBjM+nM9g29ZlpLJZPo6mUyqpKQkfT0wMKDLly9r586dkqSrV6/qjTfeUHV1tUKhUNaDAQDGl2fwQ6GQ4vG4enp6NHPmTLW0tOj5559PP15YWKj6+vr0dW1trdatW0fsAeAW4xn8goICVVZWqq6uTrZtq6KiQnPmzFFjY6NCoZDC4fBEzAkAGCOfM9pN+gnS3d2dr299S+H+pItduNiFi124xnIPn1faAoAhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4AhCD4AGMKfyaG2tjY1NDTItm0tX75cq1atGvb4F198oePHj6ugoEAzZszQ008/rTvuuCMnAwMAsuP5DN+2bdXX16umpkb79u1Tc3Ozurq6hp25++67FY1G9eabb2rJkiX64IMPcjYwACA7nsHv6OhQWVmZSktL5ff7VV5ertbW1mFn7rvvPk2bNk2SNHfuXKVSqdxMCwDImuctnVQqJcuy0teWZam9vf2G55uamrRgwYJRH4vFYorFYpKkaDSqQCBws/NOSn6/n11cxy5c7MLFLsaHZ/AdxxnxMZ/PN+rZEydO6NKlS6qtrR318Ugkokgkkr5OJBIZjjm5BQIBdnEdu3CxCxe7cAWDwaw/1/OWjmVZSiaT6etkMqmSkpIR577//nt9+umnqq6u1tSpU7MeCACQG57BD4VCisfj6unp0dDQkFpaWhQOh4ed6ezs1Lvvvqvq6moVFxfnbFgAQPY8b+kUFBSosrJSdXV1sm1bFRUVmjNnjhobGxUKhRQOh/XBBx9oYGBAe/fulfSfv3698sorOR8eAJA5nzPaTfoJ0t3dna9vfUvh/qSLXbjYhYtduHJ6Dx8AMDkQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEP4MznU1tamhoYG2bat5cuXa9WqVcMeHxwc1Ntvv61Lly5p+vTp2rx5s2bNmpWTgQEA2fF8hm/bturr61VTU6N9+/apublZXV1dw840NTXp9ttv14EDB/TYY4/pww8/zNnAAIDseAa/o6NDZWVlKi0tld/vV3l5uVpbW4edOX36tJYtWyZJWrJkic6dOyfHcXIyMAAgO563dFKplCzLSl9blqX29vYbnikoKFBhYaF6e3s1Y8aMYedisZhisZgkKRqNKhgMjvkPMFmwCxe7cLELF7sYO89n+KM9U/f5fDd9RpIikYii0aii0aheffXVm5lzUmMXLnbhYhcuduEayy48g29ZlpLJZPo6mUyqpKTkhmeuXbum/v5+FRUVZT0UAGD8eQY/FAopHo+rp6dHQ0NDamlpUTgcHnZm0aJF+vrrryVJp06d0r333jvqM3wAQP4U1NbW1v7TgSlTpqisrEwHDhzQ0aNH9fDDD2vJkiVqbGzUwMCAgsGg7rzzTp08eVIfffSRfv75Z23YsCGjZ/j33HPPeP05/u+xCxe7cLELF7twZbsLn8Ov0wCAEXilLQAYguADgCEyemuFseBtGVxeu/jiiy90/PhxFRQUaMaMGXr66ad1xx135Gna3PLaxd9OnTqlvXv3avfu3QqFQhM85cTIZBctLS36+OOP5fP5dNddd2nTpk15mDT3vHaRSCR08OBB9fX1ybZtPfnkk1q4cGGeps2dd955R2fOnFFxcbH27Nkz4nHHcdTQ0KCzZ89q2rRpqqqqyuy+vpND165dc5599lnn119/dQYHB52XXnrJuXz58rAzR48edQ4fPuw4juOcPHnS2bt3by5HyptMdvHDDz84AwMDjuM4zrFjx4zeheM4Tn9/v7N9+3anpqbG6ejoyMOkuZfJLrq7u52XX37Z6e3tdRzHca5evZqPUXMuk10cOnTIOXbsmOM4jnP58mWnqqoqH6Pm3I8//uhcvHjRefHFF0d9/Ntvv3Xq6uoc27adn376ydmyZUtGXzent3R4WwZXJru47777NG3aNEnS3LlzlUql8jFqzmWyC0lqbGzUypUrNXXq1DxMOTEy2cXx48f16KOPpn/zrbi4OB+j5lwmu/D5fOrv75ck9ff3j3hN0GQxf/78f/xNx9OnT+uRRx6Rz+fTvHnz1NfXpytXrnh+3ZwGf7S3ZfjfiN3obRkmm0x28d+ampq0YMGCiRhtwmWyi87OTiUSCS1atGiix5tQmeyiu7tb8Xhc27Zt02uvvaa2traJHnNCZLKL1atX65tvvtHGjRu1e/duVVZWTvSYt4RUKqVAIJC+9urJ33Ia/NGeqWf7tgz/727mz3nixAldunRJK1euzPVYeeG1C9u2deTIEa1fv34ix8qLTH4ubNtWPB7Xjh07tGnTJh06dEh9fX0TNeKEyWQXzc3NWrZsmQ4dOqQtW7bowIEDsm17oka8ZWTbzZwGn7dlcGWyC0n6/vvv9emnn6q6unrS3srw2sXAwIAuX76snTt36plnnlF7e7veeOMNXbx4MR/j5lQmPxczZ87Ugw8+KL/fr1mzZikYDCoej0/0qDmXyS6ampq0dOlSSdK8efM0ODg4Ke8IeLEsS4lEIn19o578r5wGn7dlcGWyi87OTr377ruqrq6etPdpJe9dFBYWqr6+XgcPHtTBgwc1d+5cVVdXT8rf0snk52Lx4sU6d+6cJOn3339XPB5XaWlpPsbNqUx2EQgE0rvo6urS4ODgiHflNUE4HNaJEyfkOI4uXLigwsLCjIKf81fanjlzRkeOHJFt26qoqNATTzyhxsZGhUIhhcNh/fXXX3r77bfV2dmpoqIibd68eVL+MEveu9i1a5d++eUX/etf/5L0nx/uV155Jc9T54bXLv5bbW2t1q1bNymDL3nvwnEcvf/++2pra9OUKVP0xBNP6KGHHsr32DnhtYuuri4dPnxYAwMDkqS1a9fq/vvvz/PU42///v06f/68ent7VVxcrDVr1mhoaEiStGLFCjmOo/r6en333Xe67bbbVFVVldF/H7y1AgAYglfaAoAhCD4AGILgA4AhCD4AGILgA4AhCD4AGILgA4Ah/g2E85s+YeBU/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0,N), H.history['loss'], label = 'train_loss')\n",
    "plt.plot(np.arange(0,N), H.history['val_loss'], label = 'val_loss')\n",
    "plt.plot(np.arange(0,N), H.history['accuracy'], label = 'train_acc')\n",
    "plt.plot(np.arange(0,N), H.history['val_accuracy'], label = 'val_acc')\n",
    "plt.title('Training Loss and Accuracy on car-type-nlp classifier')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend(loc='lower left')\n",
    "plt.savefig('car-type-nlp3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'content':abc, 'type':Y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO 特仕車 配備 倒車 油電 系統 置物 LC CAMRY 室內 顯影 自動 收鏡 LE ...</td>\n",
       "      <td>Toyota_camry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>聲音 RAV4 高興 異音 小聲 技師 不平 路面 先進 牽來 擾人 後門 關門 備胎 外殼...</td>\n",
       "      <td>Toyota_rav4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>記憶 副駕 調整 後座 這就 S60 副駕駛 駕駛 要載 位置 椅子 功能 座椅 常常 三組...</td>\n",
       "      <td>Volvo_s60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>順益 經銷商 價格 匯豐 裕益 折價 09 領牌 服務 lanceriO 出廠 想問 這三家...</td>\n",
       "      <td>Mitsubishi_lancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>系統 定速 油門 接手 暴衝 自動 速度 購入 2011 focus 1.84 10 跑國 ...</td>\n",
       "      <td>Ford_focus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163284</th>\n",
       "      <td>V60 316 配備 BMW 導航 價格 系統 二手價 S60 Volvo 選配 豪華 不錯...</td>\n",
       "      <td>Volvo_v60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163285</th>\n",
       "      <td>C300 行燈 XD 2011 旅行車 渦輪 不錯 霧燈 引擎 開箱 ES 馬力 腳踏墊 牽...</td>\n",
       "      <td>Benz_c200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163286</th>\n",
       "      <td>顯示器 抬頭 車美仕 Toyota 幫忙 鑑定 說明書 授權 原廠 汽車 兩光 生產 Alt...</td>\n",
       "      <td>Toyota_altis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163287</th>\n",
       "      <td>更換 車門 保險 零件 LIVINA 舊品 賠償 主張 簡單 折舊 經濟 拍照 修復 價格 ...</td>\n",
       "      <td>Nissan_livina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163288</th>\n",
       "      <td>S8 動力 旗艦 車型 系統 房車 配備 性能 Audi 懸吊 轉向 A8 標準 項目 56...</td>\n",
       "      <td>Audi_tt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163289 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content               type\n",
       "0       NO 特仕車 配備 倒車 油電 系統 置物 LC CAMRY 室內 顯影 自動 收鏡 LE ...       Toyota_camry\n",
       "1       聲音 RAV4 高興 異音 小聲 技師 不平 路面 先進 牽來 擾人 後門 關門 備胎 外殼...        Toyota_rav4\n",
       "2       記憶 副駕 調整 後座 這就 S60 副駕駛 駕駛 要載 位置 椅子 功能 座椅 常常 三組...          Volvo_s60\n",
       "3       順益 經銷商 價格 匯豐 裕益 折價 09 領牌 服務 lanceriO 出廠 想問 這三家...  Mitsubishi_lancer\n",
       "4       系統 定速 油門 接手 暴衝 自動 速度 購入 2011 focus 1.84 10 跑國 ...         Ford_focus\n",
       "...                                                   ...                ...\n",
       "163284  V60 316 配備 BMW 導航 價格 系統 二手價 S60 Volvo 選配 豪華 不錯...          Volvo_v60\n",
       "163285  C300 行燈 XD 2011 旅行車 渦輪 不錯 霧燈 引擎 開箱 ES 馬力 腳踏墊 牽...          Benz_c200\n",
       "163286  顯示器 抬頭 車美仕 Toyota 幫忙 鑑定 說明書 授權 原廠 汽車 兩光 生產 Alt...       Toyota_altis\n",
       "163287  更換 車門 保險 零件 LIVINA 舊品 賠償 主張 簡單 折舊 經濟 拍照 修復 價格 ...      Nissan_livina\n",
       "163288  S8 動力 旗艦 車型 系統 房車 配備 性能 Audi 懸吊 轉向 A8 標準 項目 56...            Audi_tt\n",
       "\n",
       "[163289 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_tags = pd.DataFrame(c)\n",
    "final_df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_tags.to_csv('final_df_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse\n",
    "corpus = final_df['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\BIGDAT~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.493 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "abc = []\n",
    "for x in corpus:\n",
    "    c = \" \".join(jieba.analyse.extract_tags(x, topK=100))\n",
    "    abc.append(c)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(abc, columns=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('abc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('final_df_tags.csv')\n",
    "corpus = df['content'].tolist()\n",
    "Y = df['type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for x in corpus:\n",
    "    a.append(x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# splitting data into training set and test set. If random_state is set to an integer, the split datasets are fixed.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(a, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing text vocab dict: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 130631/130631 [00:03<00:00, 39064.18it/s]\n",
      "Preparing text vocab dict: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32658/32658 [00:00<00:00, 37755.34it/s]\n",
      "2020-09-11 18:14:12,930 [DEBUG] kashgari - --- Build vocab dict finished, Total: 139663 ---\n",
      "2020-09-11 18:14:12,931 [DEBUG] kashgari - Top-10: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '原廠', '不錯', '配備', '價格', '台灣', '10']\n",
      "Preparing classification label vocab dict: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 130631/130631 [00:00<00:00, 1088789.56it/s]\n",
      "Preparing classification label vocab dict: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32658/32658 [00:00<00:00, 1019588.08it/s]\n",
      "Calculating sequence length: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 130631/130631 [00:00<00:00, 1360567.88it/s]\n",
      "Calculating sequence length: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32658/32658 [00:00<00:00, 1088808.71it/s]\n",
      "2020-09-11 18:14:13,926 [DEBUG] kashgari - Calculated sequence length = 100\n",
      "2020-09-11 18:14:14,278 [DEBUG] kashgari - Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "layer_embedding (Embedding)  (None, None, 100)         13966300  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               91600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 58)                5858      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 58)                0         \n",
      "=================================================================\n",
      "Total params: 14,127,886\n",
      "Trainable params: 14,127,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2041/2041 [==============================] - 216s 106ms/step - loss: 2.5660 - accuracy: 0.2751 - val_loss: 1.3636 - val_accuracy: 0.5392\n",
      "Epoch 2/3\n",
      "2041/2041 [==============================] - 216s 106ms/step - loss: 0.9198 - accuracy: 0.7046 - val_loss: 0.7300 - val_accuracy: 0.7751\n",
      "Epoch 3/3\n",
      "1715/2041 [========================>.....] - ETA: 33s - loss: 0.5579 - accuracy: 0.8212"
     ]
    }
   ],
   "source": [
    "import kashgari\n",
    "from kashgari.tasks.classification import CNN_LSTM_Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "kashgari.config.use_cudnn_cell = True\n",
    "import logging\n",
    "logging.basicConfig(level='DEBUG')\n",
    "\n",
    "tf_board = TensorBoard(log_dir='tf_dir/cnn_model',\n",
    "                       histogram_freq=5, \n",
    "                       update_freq='batch')\n",
    "\n",
    "model = CNN_LSTM_Model()\n",
    "model.fit(X_train, Y_train,  X_test,Y_test,epochs=3, callbacks=[tf_board])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'cp950' codec can't encode character '\\u6ca1' in position 249266: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d231b4a5a40c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kashgari\\tasks\\abs_task_model.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_config.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'cp950' codec can't encode character '\\u6ca1' in position 249266: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-11 13:30:33,276 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 93155\n",
      "2020-09-11 13:31:45,771 [DEBUG] kashgari - predict input shape (32658, 93155) x: \n",
      "[[     2   1602    129 ...      0      0      0]\n",
      " [     2     56    251 ...      0      0      0]\n",
      " [     2   2497     36 ...      0      0      0]\n",
      " ...\n",
      " [     2   2633   2813 ...      0      0      0]\n",
      " [     2 132346 145614 ...      0      0      0]\n",
      " [     2    668   4860 ...      0      0      0]]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " [_Derived_]  OOM when allocating tensor with shape[32,93155,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node cond/then/_0/CudnnRNNV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[model_1/bidirectional/backward_lstm/StatefulPartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_160528]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-18e53af38380>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kashgari\\tasks\\classification\\abc_model.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x_data, y_data, batch_size, digits, multi_label_threshold, truncating)\u001b[0m\n\u001b[0;32m    330\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                               \u001b[0mtruncating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtruncating\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m                               multi_label_threshold=multi_label_threshold)\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kashgari\\tasks\\classification\\abc_model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x_data, batch_size, truncating, multi_label_threshold, predict_kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m                                                    max_position=self.embedding.max_position)\n\u001b[0;32m    305\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'predict input shape {np.array(tensor).shape} x: \\n{tensor}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'predict output shape {pred.shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m             \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    648\u001b[0m               *args, **kwds)\n\u001b[0;32m    649\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  [_Derived_]  OOM when allocating tensor with shape[32,93155,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node cond/then/_0/CudnnRNNV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[model_1/bidirectional/backward_lstm/StatefulPartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_160528]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_Y, test_size = 0.20, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32,   2,  19, ...,  46,   0,   0],\n",
       "       [ 16,   2,  49, ...,  98,   3,   0],\n",
       "       [ 11,   2,  35, ...,  15,   2,   0],\n",
       "       ...,\n",
       "       [  0,   0,   2, ..., 124,   4,   0],\n",
       "       [  0,   0,   0, ..., 131,  75,   7],\n",
       "       [  0,   0,   1, ..., 269,  98,  19]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 2 20 25 ... 45 50 55].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6551205440a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \"\"\"\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m     75\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    554\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 2 20 25 ... 45 50 55].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "classifier.score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big data\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17891481413436217"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.classification import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0 )\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118,  47,  22, ...,   0,   1,   1],\n",
       "       [ 32, 235,  34, ...,   0,   1,   2],\n",
       "       [ 12,  40, 111, ...,   0,   0,   2],\n",
       "       ...,\n",
       "       [  1,   3,   0, ...,  48,  14,  35],\n",
       "       [  0,   0,   0, ...,   5, 126,  49],\n",
       "       [  0,   0,   0, ...,  13,  45, 380]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6573274542225488"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.classification import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7349194684303999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.classification import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #pickle模組\n",
    "\n",
    "#儲存Model(注:save資料夾要預先建立，否則會報錯)\n",
    "with open('clf_rf.pickle', 'wb') as f:\n",
    "    pickle.dump(classifier, f)\n",
    "\n",
    "#讀取Model\n",
    "# with open('clf.pickle', 'rb') as f:\n",
    "#     clf2 = pickle.load(f)\n",
    "#     #測試讀取後的Model\n",
    "#     print(clf2.predict(X[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['阿福 課程 畢業 換車 預計 幫出 20 30 剩下 預算 90 60 區間 沒車 決定 幫家裡 90 安全 妥善 空間 喜歡 Toyota 討厭 Honda 雙田 mazda3 sx4']\n",
    "word = cv.transform(s).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mazda_mazda3'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(classifier.predict(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clf_nb_label.pickle', 'wb') as f:\n",
    "    pickle.dump(encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = 'nb_vc.pkl'\n",
    "with open(feature_path, 'wb') as fw:\n",
    "    pickle.dump(cv.vocabulary_, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'車窗 鑰匙 升降 斷電 電動 電力 功能 2010 Altis 1.8 還可以 先進 供電 買來 拔完 車門 開門 狀態 CAMRY 手冊 啟動 開啟 熄火 印象 停好 英文字 轉到 還得 開個 來關 剛滿 無意 順路 原廠 問了 服務 上來 這款 關著 試過 關門 TOYOTA 車是 翻閱 防盜 後照鏡 收折 鎖住 透氣 忘記 短暫 重複 電門 夜間 車庫 時關 一分鐘 自動 沒測過 按鈕 車型 yaris 適合 設定 42 內且 副駕駛座 門皆 馬上 喜歡 掙扎 說明 閱讀 注意到 解答 拔出 永久 提醒 竟然 回去 位置 一年 代表'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toyota_altis'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(max_features=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.20131\ttest-merror:0.22197\n",
      "[1]\ttrain-merror:0.19265\ttest-merror:0.21796\n",
      "[2]\ttrain-merror:0.18734\ttest-merror:0.21554\n",
      "[3]\ttrain-merror:0.18395\ttest-merror:0.21407\n",
      "[4]\ttrain-merror:0.18049\ttest-merror:0.21257\n",
      "[5]\ttrain-merror:0.17748\ttest-merror:0.21162\n",
      "predicting, classification error=0.211617\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#加载numpy的数组到DMatrix对象\n",
    "xg_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix( X_test, label=y_test)\n",
    "#1.训练模型\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 58\n",
    "\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 6\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist )\n",
    "\n",
    "pred = bst.predict( xg_test )\n",
    "print ('predicting, classification error=%f' % (sum( int(pred[i]) != y_test[i] for i in range(len(y_test))) / float(len(y_test)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600154667.100448\n"
     ]
    }
   ],
   "source": [
    "# 14:22\n",
    "import time\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2., 20., 25., ..., 45., 50., 55.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big data\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7883826321268909"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.classification import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model('xgboost_model0915.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst2 = xgb.Booster(model_file='xgboost_model0915.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2., 20., 25., ..., 45., 50., 55.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst2.predict(xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.DMatrix at 0x2d2464ef988>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #pickle模組\n",
    "\n",
    "#儲存Model(注:save資料夾要預先建立，否則會報錯)\n",
    "with open('bst.pickle', 'wb') as f:\n",
    "    pickle.dump(bst, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
